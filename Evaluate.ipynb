{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/DeepLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, LeakyReLU, Concatenate\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import DenseNet169\n",
    "import numpy as np\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpscaleBlock(Model):\n",
    "    def __init__(self, filters, name):      \n",
    "        super(UpscaleBlock, self).__init__()\n",
    "        self.up = UpSampling2D(size=(2, 2), interpolation='bilinear', name=name+'_upsampling2d')\n",
    "        self.concat = Concatenate(name=name+'_concat') # Skip connection        \n",
    "        self.convA = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same', name=name+'_convA')\n",
    "        self.reluA = LeakyReLU(alpha=0.2)\n",
    "        self.convB = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same', name=name+'_convB')\n",
    "        self.reluB = LeakyReLU(alpha=0.2)\n",
    "    \n",
    "    def call(self, x):        \n",
    "        b = self.reluB( self.convB( self.reluA( self.convA( self.concat( [self.up(x[0]), x[1]] ) ) ) ) )\n",
    "        return b \n",
    "\n",
    "class Encoder(Model):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()                \n",
    "        self.base_model = DenseNet169(input_shape=(None, None, 3), include_top=False, weights='imagenet')   \n",
    "        print('Base model loaded {}'.format(DenseNet169.__name__))\n",
    "        \n",
    "        # Create encoder model that produce final features along with multiple intermediate features\n",
    "        outputs = [self.base_model.outputs[-1]]\n",
    "        for name in ['pool1', 'pool2_pool', 'pool3_pool', 'conv1/relu'] : outputs.append( self.base_model.get_layer(name).output )        \n",
    "        self.encoder = Model(inputs=self.base_model.inputs, outputs=outputs)\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "class Decoder(Model):\n",
    "    def __init__(self, decode_filters):\n",
    "        super(Decoder, self).__init__()        \n",
    "        self.conv2 =  Conv2D(filters=decode_filters, kernel_size=1, padding='same', name='conv2')        \n",
    "        self.up1 = UpscaleBlock(filters=decode_filters//2,  name='up1')\n",
    "        self.up2 = UpscaleBlock(filters=decode_filters//4,  name='up2')\n",
    "        self.up3 = UpscaleBlock(filters=decode_filters//8,  name='up3')\n",
    "        self.up4 = UpscaleBlock(filters=decode_filters//16, name='up4')        \n",
    "        self.conv3 = Conv2D(filters=1, kernel_size=3, strides=1, padding='same', name='conv3')       \n",
    "\n",
    "    def call(self, features):        \n",
    "        x, pool1, pool2, pool3, conv1 = features[0], features[1], features[2], features[3], features[4]\n",
    "        up0 = self.conv2(x)        \n",
    "        up1 = self.up1([up0, pool3])        \n",
    "        up2 = self.up2([up1, pool2])        \n",
    "        up3 = self.up3([up2, pool1])        \n",
    "        up4 = self.up4([up3, conv1])        \n",
    "        return self.conv3( up4 )\n",
    "    \n",
    "class DepthEstimate(Model):\n",
    "    def __init__(self):\n",
    "        super(DepthEstimate, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder( decode_filters = int(self.encoder.layers[-1].output[0].shape[-1] // 2 ) )\n",
    "        print('\\nModel created.')\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.decoder( self.encoder(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DepthEstimate()\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "print('Model weights loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and evalute on Eigen's test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "def load_test_data():    \n",
    "    print('Loading test data...', end='')\n",
    "    \n",
    "    rgb = np.load('data/test/eigen_test_rgb.npy')\n",
    "    depth = np.load('data/test/eigen_test_depth.npy')\n",
    "    crop = np.load('data/test/eigen_test_crop.npy')\n",
    "    print('Test data loaded.\\n')\n",
    "    \n",
    "    return rgb, depth, crop\n",
    "\n",
    "def DepthNorm(x, maxDepth):\n",
    "    return maxDepth / x\n",
    "\n",
    "def predict(model, images, minDepth=10, maxDepth=1000, batch_size=2):\n",
    "    # Support multiple RGBs, one RGB image, even grayscale \n",
    "    if len(images.shape) < 3: images = np.stack((images,images,images), axis=2)\n",
    "    if len(images.shape) < 4: images = images.reshape((1, images.shape[0], images.shape[1], images.shape[2]))\n",
    "    # Compute predictions\n",
    "    predictions = model.predict(images, batch_size=batch_size)\n",
    "    # Put in expected range\n",
    "    return np.clip(DepthNorm(predictions, maxDepth=1000), minDepth, maxDepth) / maxDepth\n",
    "\n",
    "def scale_up(scale, images):\n",
    "    from skimage.transform import resize\n",
    "    scaled = []\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        img = images[i]\n",
    "        output_shape = (scale * img.shape[0], scale * img.shape[1])\n",
    "        scaled.append( resize(img, output_shape, order=1, preserve_range=True, mode='reflect', anti_aliasing=True ) )\n",
    "\n",
    "    return np.stack(scaled)\n",
    "\n",
    "def evaluate(model, rgb, depth, crop, batch_size=6):\n",
    "    def compute_errors(gt, pred):\n",
    "        thresh = np.maximum((gt / pred), (pred / gt))\n",
    "        \n",
    "        a1 = (thresh < 1.25   ).mean()\n",
    "        a2 = (thresh < 1.25 ** 2).mean()\n",
    "        a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "        abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "\n",
    "        rmse = (gt - pred) ** 2\n",
    "        rmse = np.sqrt(rmse.mean())\n",
    "\n",
    "        log_10 = (np.abs(np.log10(gt)-np.log10(pred))).mean()\n",
    "\n",
    "        return a1, a2, a3, abs_rel, rmse, log_10\n",
    "\n",
    "    depth_scores = np.zeros((6, len(rgb))) # six metrics\n",
    "\n",
    "    bs = batch_size\n",
    "\n",
    "    for i in range(len(rgb)//bs):    \n",
    "        x = rgb[(i)*bs:(i+1)*bs,:,:,:]\n",
    "        \n",
    "        # Compute results\n",
    "        true_y = depth[(i)*bs:(i+1)*bs,:,:]\n",
    "        pred_y = scale_up(2, predict(model, x/255, minDepth=10, maxDepth=1000, batch_size=bs)[:,:,:,0]) * 10.0\n",
    "        \n",
    "        # Test time augmentation: mirror image estimate\n",
    "        pred_y_flip = scale_up(2, predict(model, x[...,::-1,:]/255, minDepth=10, maxDepth=1000, batch_size=bs)[:,:,:,0]) * 10.0\n",
    "\n",
    "        # Crop based on Eigen et al. crop\n",
    "        true_y = true_y[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
    "        pred_y = pred_y[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
    "        pred_y_flip = pred_y_flip[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
    "        \n",
    "        # Compute errors per image in batch\n",
    "        for j in range(len(true_y)):\n",
    "            errors = compute_errors(true_y[j], (0.5 * pred_y[j]) + (0.5 * np.fliplr(pred_y_flip[j])))\n",
    "            \n",
    "            for k in range(len(errors)):\n",
    "                depth_scores[k][(i*bs)+j] = errors[k]\n",
    "\n",
    "    e = depth_scores.mean(axis=1)\n",
    "\n",
    "    print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('a1', 'a2', 'a3', 'rel', 'rms', 'log_10'))\n",
    "    print(\"{:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}\".format(e[0],e[1],e[2],e[3],e[4],e[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb, depth, crop = load_test_data()\n",
    "evaluate(model, rgb, depth, crop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu] *",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
