{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages and Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow keras pillow matplotlib scikit-learn scikit-image opencv-python pydot GraphViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/DeepLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, LeakyReLU, Concatenate\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import DenseNet169\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size     = 8\n",
    "learning_rate  = 0.0001\n",
    "epochs         = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpscaleBlock(Model):\n",
    "    def __init__(self, filters, name):      \n",
    "        super(UpscaleBlock, self).__init__()\n",
    "        self.up = UpSampling2D(size=(2, 2), interpolation='bilinear', name=name+'_upsampling2d')\n",
    "        self.concat = Concatenate(name=name+'_concat') # Skip connection        \n",
    "        self.convA = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same', name=name+'_convA')\n",
    "        self.reluA = LeakyReLU(alpha=0.2)\n",
    "        self.convB = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same', name=name+'_convB')\n",
    "        self.reluB = LeakyReLU(alpha=0.2)\n",
    "    \n",
    "    def call(self, x):        \n",
    "        b = self.reluB( self.convB( self.reluA( self.convA( self.concat( [self.up(x[0]), x[1]] ) ) ) ) )\n",
    "        return b \n",
    "\n",
    "class Encoder(Model):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()                \n",
    "        self.base_model = DenseNet169(input_shape=(None, None, 3), include_top=False, weights='imagenet')   \n",
    "        print('Base model loaded {}'.format(DenseNet169.__name__))\n",
    "        \n",
    "        # Create encoder model that produce final features along with multiple intermediate features\n",
    "        outputs = [self.base_model.outputs[-1]]\n",
    "        for name in ['pool1', 'pool2_pool', 'pool3_pool', 'conv1/relu'] : outputs.append( self.base_model.get_layer(name).output )        \n",
    "        self.encoder = Model(inputs=self.base_model.inputs, outputs=outputs)\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "class Decoder(Model):\n",
    "    def __init__(self, decode_filters):\n",
    "        super(Decoder, self).__init__()        \n",
    "        self.conv2 =  Conv2D(filters=decode_filters, kernel_size=1, padding='same', name='conv2')        \n",
    "        self.up1 = UpscaleBlock(filters=decode_filters//2,  name='up1')\n",
    "        self.up2 = UpscaleBlock(filters=decode_filters//4,  name='up2')\n",
    "        self.up3 = UpscaleBlock(filters=decode_filters//8,  name='up3')\n",
    "        self.up4 = UpscaleBlock(filters=decode_filters//16, name='up4')        \n",
    "        self.conv3 = Conv2D(filters=1, kernel_size=3, strides=1, padding='same', name='conv3')       \n",
    "\n",
    "    def call(self, features):        \n",
    "        x, pool1, pool2, pool3, conv1 = features[0], features[1], features[2], features[3], features[4]\n",
    "        up0 = self.conv2(x)        \n",
    "        up1 = self.up1([up0, pool3])        \n",
    "        up2 = self.up2([up1, pool2])        \n",
    "        up3 = self.up3([up2, pool1])        \n",
    "        up4 = self.up4([up3, conv1])        \n",
    "        return self.conv3( up4 )\n",
    "    \n",
    "class DepthEstimate(Model):\n",
    "    def __init__(self):\n",
    "        super(DepthEstimate, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder( decode_filters = int(self.encoder.layers[-1].output[0].shape[-1] // 2 ) )\n",
    "        print('\\nModel created.')\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.decoder( self.encoder(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DepthEstimate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, csv_file='data/nyu2_train.csv', DEBUG=False):\n",
    "        self.shape_rgb = (480, 640, 3)\n",
    "        self.shape_depth = (240, 320, 1)\n",
    "        self.read_nyu_data(csv_file, DEBUG=DEBUG)\n",
    "\n",
    "    def nyu_resize(self, img, resolution=480, padding=6):\n",
    "        from skimage.transform import resize\n",
    "        return resize(img, (resolution, int(resolution*4/3)), preserve_range=True, mode='reflect', anti_aliasing=True )\n",
    "\n",
    "    def read_nyu_data(self, csv_file, DEBUG=False):\n",
    "        csv = open(csv_file, 'r').read()\n",
    "        nyu2_train = list((row.split(',') for row in (csv).split('\\n') if len(row) > 0))\n",
    "\n",
    "        # Dataset shuffling happens here\n",
    "        nyu2_train = shuffle(nyu2_train, random_state=0)\n",
    "\n",
    "        # Test on a smaller dataset\n",
    "        if DEBUG: nyu2_train = nyu2_train[:10]\n",
    "        \n",
    "        # A vector of RGB filenames.\n",
    "        self.filenames = [i[0] for i in nyu2_train]\n",
    "\n",
    "        # A vector of depth filenames.\n",
    "        self.labels = [i[1] for i in nyu2_train]\n",
    "\n",
    "        # Length of dataset\n",
    "        self.length = len(self.filenames)\n",
    "\n",
    "    def _parse_function(self, filename, label): \n",
    "        # Read images from disk\n",
    "        image_decoded = tf.image.decode_jpeg(tf.io.read_file(filename))\n",
    "        depth_resized = tf.image.resize(tf.image.decode_jpeg(tf.io.read_file(label)), [self.shape_depth[0], self.shape_depth[1]])\n",
    "\n",
    "        # Format\n",
    "        rgb = tf.image.convert_image_dtype(image_decoded, dtype=tf.float32)\n",
    "        depth = tf.image.convert_image_dtype(depth_resized / 255.0, dtype=tf.float32)\n",
    "        \n",
    "        # Normalize the depth values (in cm)\n",
    "        depth = 1000 / tf.clip_by_value(depth * 1000, 10, 1000)\n",
    "\n",
    "        return rgb, depth\n",
    "\n",
    "    def get_batched_dataset(self, batch_size):\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices((self.filenames, self.labels))\n",
    "        self.dataset = self.dataset.shuffle(buffer_size=len(self.filenames), reshuffle_each_iteration=True)\n",
    "        self.dataset = self.dataset.repeat()\n",
    "        self.dataset = self.dataset.map(map_func=self._parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        self.dataset = self.dataset.batch(batch_size=batch_size)\n",
    "\n",
    "        return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader()\n",
    "train_generator = dl.get_batched_dataset(batch_size)\n",
    "\n",
    "print('Data loader ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_loss_function(y_true, y_pred, theta=0.1, maxDepthVal=1000.0/10.0):\n",
    "    \n",
    "    # Point-wise depth\n",
    "    l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)\n",
    "\n",
    "    # Edges\n",
    "    dy_true, dx_true = tf.image.image_gradients(y_true)\n",
    "    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n",
    "    l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)\n",
    "\n",
    "    # Structural similarity (SSIM) index\n",
    "    l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, maxDepthVal)) * 0.5, 0, 1)\n",
    "\n",
    "    # Weights\n",
    "    w1 = 1.0\n",
    "    w2 = 1.0\n",
    "    w3 = theta\n",
    "\n",
    "    return (w1 * l_ssim) + (w2 * K.mean(l_edges)) + (w3 * K.mean(l_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate, amsgrad=True)\n",
    "model.compile(loss=depth_loss_function, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint callback\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "model.fit(train_generator, epochs=5, steps_per_epoch=dl.length//batch_size, callbacks=[cp_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu] *",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
